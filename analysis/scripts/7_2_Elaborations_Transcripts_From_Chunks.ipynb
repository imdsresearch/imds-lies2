{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "current_file_name = \"7_2_Elaborations_Transcripts_From_Chunks\"\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = f\"logs/{current_file_name}/{dt_string}.log\"\n",
    "logging.basicConfig(level=logging.INFO, filename=log_file,filemode=\"w\", format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# https://blog.sentry.io/logging-in-python-a-developers-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import io\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "import grpc\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.pages import *\n",
    "from helpers.constants import *\n",
    "from helpers.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens/openai_key.txt\", \"r\") as file:\n",
    "    OPENAI_API_KEY = file.read().rstrip()\n",
    "\n",
    "# Set environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MODE = \"openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MODE == \"openai\"\n",
    "GLOBAL_FORMAT = \".wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_of_paths(root_path):\n",
    "    # There are folders in the root path named after the respondents\n",
    "    # Each of these folders contains folders for elaborations \n",
    "    # Those folders contains the audio files in aac/wav format\n",
    "    # Create dictionary with the paths to the audio files, where the key is subfolder name and the value is the list of audio files\n",
    "    # FG\n",
    "    #     respondent_104\n",
    "    #         elaboration_1_1\n",
    "    #             elaboration_1_1_chunk_0.wav\n",
    "    #             elaboration_1_1_chunk_1.wav\n",
    "\n",
    "    dict_of_paths = {}\n",
    "    for respondent in os.listdir(root_path):\n",
    "        dict_of_paths[respondent] = {}\n",
    "        for elaboration in os.listdir(f\"{root_path}/{respondent}\"):\n",
    "            dict_of_paths[respondent][elaboration] = []\n",
    "            for audio_file in os.listdir(f\"{root_path}/{respondent}/{elaboration}\"):\n",
    "                if audio_file.endswith(GLOBAL_FORMAT):\n",
    "                    dict_of_paths[respondent][elaboration].append(f\"{root_path}/{respondent}/{elaboration}/{audio_file}\")\n",
    "\n",
    "    return dict_of_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_recordings_fg_path = \"data/6_2_Remove_Pauses/FG\"\n",
    "extracted_recordings_h_path = \"data/6_2_Remove_Pauses/H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_paths = get_dict_of_paths(extracted_recordings_fg_path)\n",
    "h_paths = get_dict_of_paths(extracted_recordings_h_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def transcribe_onprem_openai(local_file_path: str):\n",
    "    logging.info(f\"Transcribing {local_file_path}\")\n",
    "\n",
    "    audio_file = open(local_file_path, \"rb\")\n",
    "\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "        file=audio_file,\n",
    "        model=\"whisper-1\",\n",
    "        language=\"en\",\n",
    "        response_format=\"verbose_json\",\n",
    "        temperature=0.0, \n",
    "        timestamp_granularities=[\"word\", \"segment\"],\n",
    "        prompt=\"Umm, let me think like, hmm... Okay, here's what I'm, like, thinking. Uh. Um. Well. Er. Ah. You know, like. Erm.\"\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Transcription of {local_file_path} complete\")\n",
    "\n",
    "    return transcript, transcript.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(path_dict, variant, fixing=[]):\n",
    "    # For each respondent, transcribe all the audio files and save the transcript\n",
    "    for respondent, paths in path_dict.items():\n",
    "        logging.info(f\"Transcribing {respondent}\")\n",
    "        respondent_path = f\"data\\\\7_2_Elaborations_Transcripts_From_Chunks\\\\{variant}\\\\{respondent}\"\n",
    "\n",
    "        if os.path.exists(respondent_path):\n",
    "            logging.info(f\"Folder {respondent_path} already exists\")\n",
    "            # continue\n",
    "        else:\n",
    "            os.makedirs(respondent_path, exist_ok=True)\n",
    "\n",
    "        for elaboration, audio_files in paths.items():\n",
    "            for path in audio_files:\n",
    "                logging.info(f\"Transcribing {path} using {GLOBAL_MODE}\")\n",
    "                print(f\"Transcribing {path} using {GLOBAL_MODE}\")\n",
    "\n",
    "                response, transcript = transcribe_onprem_openai(path)\n",
    "\n",
    "                file_name_transcript = path.split(\"\\\\\")[-1].replace(GLOBAL_FORMAT, \".txt\")\n",
    "                file_name_response = path.split(\"\\\\\")[-1].replace(GLOBAL_FORMAT, \"_response.json\")\n",
    "\n",
    "                transcript_path = file_name_transcript.replace(\"6_2_Remove_Pauses\", current_file_name)\n",
    "                response_path = file_name_response.replace(\"6_2_Remove_Pauses\", current_file_name)\n",
    "\n",
    "                # Create folders on path if they don't exist\n",
    "                os.makedirs(f\"{respondent_path}\\\\{elaboration}\", exist_ok=True)\n",
    "\n",
    "                with open(transcript_path, \"w\") as f:\n",
    "                    # Sanitaze transcript to remove \\ufffd\n",
    "                    transcript = transcript.replace(\"\\ufffd\", \"\")\n",
    "                    f.write(transcript)\n",
    "\n",
    "                with open(response_path, \"w\") as f:\n",
    "                    try:\n",
    "                        f.write(response.model_dump_json())\n",
    "                    except:\n",
    "                        dump = response.model_dump_json()\n",
    "                        dump = dump.replace(\"\\ufffd\", \"\")\n",
    "                        f.write(dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transcript(fg_paths, \"FG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_transcript(h_paths, \"H\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
