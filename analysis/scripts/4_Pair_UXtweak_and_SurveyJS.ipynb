{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "current_file_name = \"4_Pair_UXtweak_and_SurveyJS\"\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = f\"logs/{current_file_name}/{dt_string}.log\"\n",
    "logging.basicConfig(level=logging.INFO, filename=log_file,filemode=\"w\", format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# https://blog.sentry.io/logging-in-python-a-developers-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.questions import *\n",
    "from helpers.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "respondents_fg = pd.read_csv(wd + '2 UXtweak CSVs\\\\[DP Lies] Final 1 FG\\\\[DP Lies] Final 1 FG - Respondents.csv')\n",
    "respondents_h = pd.read_csv(wd + '2 UXtweak CSVs\\\\[DP Lies] Final 1 H\\\\[DP Lies] Final 1 H - Respondents.csv')\n",
    "\n",
    "logging.info(\"Data read in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_respondents(respondents_out):\n",
    "    respondents = respondents_out.copy(deep=True)\n",
    "    \n",
    "    respondents = respondents[respondents['location'] != 'SK']\n",
    "    respondents = respondents[respondents['status'] == 'completed']\n",
    "    respondents = respondents[respondents['included in analysis'] == True]\n",
    "\n",
    "    respondents['ended_at'] = pd.to_datetime(respondents['started at']) + pd.to_timedelta(respondents['time taken'])\n",
    "\n",
    "    drop_cols = ['identifier', 'ip', 'status', 'included in analysis', 'questions answered',\n",
    "                 'tasks completed', 'tasks skipped', 'tasks closed', 'tasks successful']\n",
    "    respondents = respondents.drop(drop_cols, axis=1)\n",
    "\n",
    "    respondents = respondents[respondents['time taken'] > '00:10:00']\n",
    "\n",
    "    respondents = respondents.sort_values(by='ended_at')\n",
    "\n",
    "    return respondents\n",
    "\n",
    "clean_respondents_fg = clean_respondents(respondents_fg)\n",
    "clean_respondents_h = clean_respondents(respondents_h)\n",
    "\n",
    "logging.info(\"Respondents cleaned\")\n",
    "logging.info(\"Respondents FG: \" + str(clean_respondents_fg.shape))\n",
    "logging.info(\"Respondents H: \" + str(clean_respondents_h.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_respondents_fg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_respondents_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_big_5 = pd.read_csv('data\\\\1_SurveyJS_Big5_Data_Processing\\\\1_SurveyJS_Big5_Data_Processing_data.csv')\n",
    "evaluated_big_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_answers(df, glob_all_columns):\n",
    "    # Convert all global columns to int\n",
    "    df[glob_all_columns] = df[glob_all_columns].astype(int)\n",
    "    # Concat values from all columns from glob_all_columns\n",
    "    df['encoded'] = df[glob_all_columns].apply(lambda row: ''.join(row.values.astype(str)), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_big_5_encoded = encode_answers(evaluated_big_5, glob_all_columns)\n",
    "\n",
    "evaluated_big_5_encoded_fg = evaluated_big_5_encoded[evaluated_big_5_encoded['group'] == 'FG']\n",
    "evaluated_big_5_encoded_h = evaluated_big_5_encoded[evaluated_big_5_encoded['group'] == 'H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers_from_csv(csv_df, glob_all_columns):\n",
    "    csv_df = csv_df[csv_df['type'] == 'click']\n",
    "    csv_df = csv_df[csv_df['text'].isin([\"Disagree strongly\", \"Disagree\", \"Neutral\", \"Agree\", \"Agree strongly\"])]\n",
    "\n",
    "    # From each page get only the last answer\n",
    "    csv_df = csv_df.drop_duplicates(subset=['page_name'], keep='last')\n",
    "\n",
    "    # Parse the page name to get the page number\n",
    "    csv_df['page_number'] = csv_df['page_name'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "    # Page number should be lower or equal to 81\n",
    "    csv_df = csv_df[csv_df['page_number'] <= 81]\n",
    "\n",
    "    # Get list of text answers\n",
    "    csv_df = list(csv_df[\"text\"])\n",
    "\n",
    "    # Create a dictionary with the answers\n",
    "    csv_df = dict(zip(glob_all_columns, csv_df))\n",
    "\n",
    "    return csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_big_5_answers_from_interactions(path, glob_all_columns, glob_normal_columns, glob_reversed_columns, glob_normal_likert, glob_reverse_likert):\n",
    "    # Traverse through all files in the directory\n",
    "    folders = os.listdir(path)\n",
    "    \n",
    "    df = pd.DataFrame(columns=glob_all_columns + ['order'])\n",
    "\n",
    "    for folder in folders:\n",
    "        files = os.listdir(path + \"\\\\\" + folder)\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_df = pd.read_csv(path + \"\\\\\" + folder + \"\\\\\" + file)\n",
    "\n",
    "                # Get number from the folder name\n",
    "                number = folder.split(\"_\")[1]\n",
    "                answers_dictionary = get_answers_from_csv(csv_df, glob_all_columns)\n",
    "                # If all answers are NaN, skip the file\n",
    "                if all(value is np.nan for value in answers_dictionary.values()):\n",
    "                    continue\n",
    "                answers_dictionary['order'] = number\n",
    "\n",
    "                answers_df = pd.DataFrame(answers_dictionary, index=[0])\n",
    "                df = pd.concat([df, answers_df], ignore_index=True)\n",
    "    \n",
    "    df.update(df[list(glob_normal_columns)].apply(lambda col: col.map(glob_normal_likert)))\n",
    "    df.update(df[list(glob_reversed_columns)].apply(lambda col: col.map(glob_reverse_likert)))\n",
    "\n",
    "    return df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fg = 'data\\\\3_UXtweak_Mouse_Data_Processing\\\\FG'\n",
    "path_h = 'data\\\\3_UXtweak_Mouse_Data_Processing\\\\H'\n",
    "\n",
    "extracted_fg = exctract_big_5_answers_from_interactions(path_fg, glob_all_columns, glob_normal_columns, glob_reversed_columns, glob_normal_likert, glob_reverse_likert)\n",
    "extracted_fg[\"group\"] = \"FG\"\n",
    "\n",
    "extracted_h = exctract_big_5_answers_from_interactions(path_h, glob_all_columns, glob_normal_columns, glob_reversed_columns, glob_normal_likert, glob_reverse_likert)\n",
    "extracted_h[\"group\"] = \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Fix respondent H 40\n",
    "extracted_h = extracted_h[extracted_h['order'] != '40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_fg_encoded = encode_answers(extracted_fg, glob_all_columns)\n",
    "extracted_h_encoded = encode_answers(extracted_h, glob_all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full outer join on the encoded column\n",
    "merged_fg = pd.merge(evaluated_big_5_encoded_fg, extracted_fg_encoded, on='encoded', how='inner', suffixes=('_evaluated', '_extracted'))\n",
    "merged_h = pd.merge(evaluated_big_5_encoded_h, extracted_h_encoded, on='encoded', how='inner', suffixes=('_evaluated', '_extracted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = \"data\\\\4_Pair_UXtweak_and_SurveyJS\\\\\"\n",
    "\n",
    "concatenated = pd.concat([merged_fg, merged_h], ignore_index=True)\n",
    "\n",
    "concatenated.to_csv(path_to_save + \"4_Pair_UXtweak_and_SurveyJS_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(concatenated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(evaluated_big_5_encoded_fg), len(extracted_fg_encoded), len(merged_fg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(evaluated_big_5_encoded_h), len(extracted_h_encoded), len(merged_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
