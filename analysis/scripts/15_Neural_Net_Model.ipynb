{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1715654121447,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "1X7mZJMj8yZ3"
   },
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715654122205,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "n_4oz-7f8s6L"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "if not colab:\n",
    "  current_file_name = \"15_Neural_Net_Model\"\n",
    "\n",
    "  dt_string = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  log_file = f\"logs/{current_file_name}/{dt_string}.log\"\n",
    "  logging.basicConfig(level=logging.INFO, filename=log_file,filemode=\"w\", format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "  # https://blog.sentry.io/logging-in-python-a-developers-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1715654124224,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "Mot8a7ik8s6M"
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 2383,
     "status": "error",
     "timestamp": 1715654128876,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "rO-2QYBB8s6N",
    "outputId": "8eea3a9b-4463-43a1-ce1e-48bcfef980b2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking, Dropout\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, TruePositives, TrueNegatives, FalsePositives, FalseNegatives, F1Score\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1715654145467,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "tnZe-jHp8s6O"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19579,
     "status": "ok",
     "timestamp": 1715654166089,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "GBDfvmhz83I9",
    "outputId": "1da97345-b94e-4b22-e838-f1db4f5fbed6"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1715654227368,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "yY83b8QN8s6P"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "  path_to_data = \"/content/drive/MyDrive/2 DP/3 DP Riešenie/Google Colab/trajectories_data.csv\"\n",
    "else:\n",
    "  path_to_data = \"data\\\\13_Mouse_Data_Preparation\\\\trajectories_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 2073,
     "status": "ok",
     "timestamp": 1715654230815,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "24fLP-548s6P",
    "outputId": "5e7fb200-7109-40b3-a203-12c635de7999"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1715654231736,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "SUYgQM0l8s6P",
    "outputId": "84634faa-51be-4343-da9b-40691084aca4"
   },
   "outputs": [],
   "source": [
    "print(df[[\"variant\", \"respondent\", \"page_name\", \"x\", \"y\", \"indicator_fg\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 1661,
     "status": "ok",
     "timestamp": 1715654234180,
     "user": {
      "displayName": "Peter Smreček",
      "userId": "15322263329793828626"
     },
     "user_tz": -120
    },
    "id": "GrlNwtvB8s6Q",
    "outputId": "21e42c86-d365-4cbb-8c33-4925e226e406"
   },
   "outputs": [],
   "source": [
    "normal_width = 1920\n",
    "normal_height = 1080\n",
    "\n",
    "test_respondent = df[df[\"respondent\"] == \"respondent_26\"]\n",
    "test_respondent = test_respondent[test_respondent[\"page_name\"] == \"page_5\"]\n",
    "\n",
    "# Make animation\n",
    "fig = px.scatter(test_respondent, x='x', y='y', animation_frame='seconds', range_x=[0, normal_width], range_y=[0, normal_height])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fLKTCdq8s6Q"
   },
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rY87AsPc8s6R"
   },
   "outputs": [],
   "source": [
    "train_fg_respondents = ['respondent_43', 'respondent_26', 'respondent_35', 'respondent_31', 'respondent_53', 'respondent_21', 'respondent_22', 'respondent_50', 'respondent_42', 'respondent_55', 'respondent_54', 'respondent_16', 'respondent_9', 'respondent_105', 'respondent_37', 'respondent_58', 'respondent_38', 'respondent_51', 'respondent_106', 'respondent_15', 'respondent_52', 'respondent_25', 'respondent_12', 'respondent_56', 'respondent_46', 'respondent_36']\n",
    "train_h_respondents = ['respondent_8', 'respondent_24', 'respondent_42', 'respondent_17', 'respondent_29', 'respondent_108', 'respondent_30', 'respondent_39', 'respondent_58', 'respondent_10', 'respondent_19', 'respondent_53', 'respondent_45', 'respondent_52', 'respondent_33', 'respondent_16', 'respondent_21', 'respondent_32', 'respondent_23', 'respondent_35', 'respondent_47', 'respondent_48', 'respondent_31', 'respondent_20']\n",
    "test_fg_respondents = ['respondent_104', 'respondent_18', 'respondent_34', 'respondent_40', 'respondent_45', 'respondent_48', 'respondent_49']\n",
    "test_h_respondents = ['respondent_107', 'respondent_110', 'respondent_22', 'respondent_27', 'respondent_50', 'respondent_57', 'respondent_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ridnXzs8s6R"
   },
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "train_fg = df[(df[\"variant\"] == \"FG\") & (df[\"respondent\"].isin(train_fg_respondents))]\n",
    "train_h = df[(df[\"variant\"] == \"H\") & (df[\"respondent\"].isin(train_h_respondents))]\n",
    "test_fg = df[(df[\"variant\"] == \"FG\") & (df[\"respondent\"].isin(test_fg_respondents))]\n",
    "test_h = df[(df[\"variant\"] == \"H\") & (df[\"respondent\"].isin(test_h_respondents))]\n",
    "\n",
    "# Create train and test datasets\n",
    "train_df = pd.concat([train_fg, train_h])\n",
    "test_df = pd.concat([test_fg, test_h])\n",
    "\n",
    "print(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKjuW5MQ8s6S"
   },
   "outputs": [],
   "source": [
    "print(len(train_df), len(test_df), len(train_df) + len(test_df), len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not colab:\n",
    "    train_df.to_csv(\"data\\\\15_Neural_Net_Model\\\\data\\\\train_df.csv\")\n",
    "    test_df.to_csv(\"data\\\\15_Neural_Net_Model\\\\data\\\\test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9Lq8mxO8s6S"
   },
   "source": [
    "## Data Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXcD3o768s6T"
   },
   "outputs": [],
   "source": [
    "train_grouped = train_df.groupby(['variant', 'respondent', 'page_name'])\n",
    "len(train_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoyJ-08O8s6T"
   },
   "outputs": [],
   "source": [
    "test_grouped = test_df.groupby(['variant', 'respondent', 'page_name'])\n",
    "len(test_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJZbY4nn8s6T"
   },
   "source": [
    "## Sequence Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDprbuv_8s6T"
   },
   "outputs": [],
   "source": [
    "def prepare_sequences(df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for _, group in df:\n",
    "        # Here, each group will be a DataFrame containing the rows for a specific observation\n",
    "        sequences.append(group[['x', 'y']].values)\n",
    "        labels.append(group['indicator_fg'].iloc[0])  # Assuming all values in indicator_fg are the same within a group\n",
    "\n",
    "    # Convert lists to arrays for processing\n",
    "    X = np.array(sequences, dtype=object)  # Keeping as an object array to handle variable lengths\n",
    "    y = np.array(labels, dtype=float)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swkNW9ej8s6T"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_sequences(train_grouped)\n",
    "X_val, y_val = prepare_sequences(test_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0YQPh508s6U"
   },
   "outputs": [],
   "source": [
    "print(len(X_train) + len(X_val))\n",
    "print(len(y_train) + len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaZBXftY8s6U"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKL0nPdn8s6U"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(None, 2)))  # Assuming the padding value is 0\n",
    "\n",
    "architecture = 1\n",
    "\n",
    "if architecture == 1:\n",
    "    # 1 generous-lion-25\n",
    "    # 1 raw earnest-plasma-32\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "elif architecture == 2:\n",
    "    # 2 honest-dragon-30\n",
    "    # 2 raw sleek-shape-31\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[BinaryAccuracy(), Precision(), Recall(), TruePositives(), TrueNegatives(), FalsePositives(), FalseNegatives()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FpLXxft8s6U"
   },
   "source": [
    "## Training with Variable Length Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6SIXJg18s6U"
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=32):\n",
    "    \"\"\"Generate batches of data.\"\"\"\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        end = min(start + batch_size, len(X))\n",
    "        batch_indices = indices[start:end]\n",
    "\n",
    "        max_len = max(len(X[idx]) for idx in batch_indices)  # Find max length in the batch\n",
    "        batch_x = np.array([np.pad(X[idx], ((0, max_len - len(X[idx])), (0, 0)), 'constant') for idx in batch_indices])\n",
    "        batch_y = y[batch_indices]\n",
    "\n",
    "        yield batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FealQYzc8s6V"
   },
   "source": [
    "## Initialize wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhGR9kiq8s6V"
   },
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"mouse-movement-lie-detection\")\n",
    "\n",
    "config = wandb.config\n",
    "config.epochs = 50\n",
    "config.batch_size = 64\n",
    "config.learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDRbjr3x8s6V"
   },
   "outputs": [],
   "source": [
    "run_id = wandb.run.id\n",
    "run_name = wandb.run.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Fvlvrod8s6V"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYGRgPxz8s6V"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "# Metrics placeholders\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_binary_accuracy': [],\n",
    "    'train_precision': [],\n",
    "    'train_recall': [],\n",
    "    'train_true_positives': [],\n",
    "    'train_true_negatives': [],\n",
    "    'train_false_positives': [],\n",
    "    'train_false_negatives': [],\n",
    "    'val_loss': [],\n",
    "    'val_binary_accuracy': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_true_positives': [],\n",
    "    'val_true_negatives': [],\n",
    "    'val_false_positives': [],\n",
    "    'val_false_negatives': [],\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    wandb_dict = {\"epoch\": epoch+1}\n",
    "\n",
    "    # Training phase\n",
    "    train_metrics = {'loss': [],\n",
    "                     'binary_accuracy': [],\n",
    "                     'precision': [],\n",
    "                     'recall': [],\n",
    "                     'true_positives': [],\n",
    "                     'true_negatives': [],\n",
    "                     'false_positives': [],\n",
    "                     'false_negatives': [],\n",
    "                     }\n",
    "    for X_batch, y_batch in tqdm(batch_generator(X_train, y_train, batch_size), desc=\"Training batches\"):\n",
    "        metrics = model.train_on_batch(X_batch, y_batch, return_dict=True)\n",
    "        for key in train_metrics:\n",
    "            train_metrics[key].append(metrics[key])\n",
    "\n",
    "    # Aggregate metrics for the epoch\n",
    "    for key in train_metrics:\n",
    "        history[f'train_{key}'].append(np.mean(train_metrics[key]))\n",
    "        wandb_dict[f'train_{key}'] = np.mean(train_metrics[key])\n",
    "\n",
    "    # Validation phase\n",
    "    val_metrics = {'loss': [],\n",
    "                   'binary_accuracy': [],\n",
    "                   'precision': [],\n",
    "                   'recall': [],\n",
    "                   'true_positives': [],\n",
    "                   'true_negatives': [],\n",
    "                   'false_positives': [],\n",
    "                   'false_negatives': [],\n",
    "                   }\n",
    "    for X_batch, y_batch in tqdm(batch_generator(X_val, y_val, batch_size), desc=\"Validation batches\"):\n",
    "        metrics = model.test_on_batch(X_batch, y_batch, return_dict=True)\n",
    "        for key in val_metrics:\n",
    "            val_metrics[key].append(metrics[key])\n",
    "\n",
    "    # Aggregate metrics for the epoch\n",
    "    for key in val_metrics:\n",
    "        history[f'val_{key}'].append(np.mean(val_metrics[key]))\n",
    "        wandb_dict[f'val_{key}'] = np.mean(val_metrics[key])\n",
    "\n",
    "    # Log the metrics for this epoch\n",
    "    wandb.log(wandb_dict)\n",
    "\n",
    "    # Log the results for this epoch\n",
    "    print(f\"Train loss: {history['train_loss'][-1]}, Val loss: {history['val_loss'][-1]}\")\n",
    "    print(f\"Train binary accuracy: {history['train_binary_accuracy'][-1]}, Val binary accuracy: {history['val_binary_accuracy'][-1]}\")\n",
    "    print(f\"Train precision: {history['train_precision'][-1]}, Val precision: {history['val_precision'][-1]}\")\n",
    "    print(f\"Train recall: {history['train_recall'][-1]}, Val recall: {history['val_recall'][-1]}\")\n",
    "    print(f\"Train true positives: {history['train_true_positives'][-1]}, Val true positives: {history['val_true_positives'][-1]}\")\n",
    "    print(f\"Train true negatives: {history['train_true_negatives'][-1]}, Val true negatives: {history['val_true_negatives'][-1]}\")\n",
    "    print(f\"Train false positives: {history['train_false_positives'][-1]}, Val false positives: {history['val_false_positives'][-1]}\")\n",
    "    print(f\"Train false negatives: {history['train_false_negatives'][-1]}, Val false negatives: {history['val_false_negatives'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIgvj56X8s6V"
   },
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mywkVqoQ8s6W"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Binary Accuracy plot\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.plot(history['train_binary_accuracy'], label='Train Binary Accuracy')\n",
    "plt.plot(history['val_binary_accuracy'], label='Validation Binary Accuracy')\n",
    "plt.title('Binary Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Precision plot\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.plot(history['train_precision'], label='Train Precision')\n",
    "plt.plot(history['val_precision'], label='Validation Precision')\n",
    "plt.title('Precision over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "# Recall plot\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.plot(history['train_recall'], label='Train Recall')\n",
    "plt.plot(history['val_recall'], label='Validation Recall')\n",
    "plt.title('Recall over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYQN91I28s6W"
   },
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGwgbCpe8s6X"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "  model_path = f\"/content/drive/MyDrive/2 DP/3 DP Riešenie/Google Colab/{run_name}.keras\"\n",
    "else:\n",
    "  model_path = f\"data\\\\15_Neural_Net_Model\\\\models\\\\{run_name}.keras\"\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)  # Using keras format\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2G7HzZX8s6X"
   },
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hM09DtAH8s6X"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = load_model(model_path)\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBmG2qwp8s6X"
   },
   "source": [
    "## Wandb Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ztsDl4v8s6X"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
