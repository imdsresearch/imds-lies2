{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "current_file_name = \"7_Elaborations_Transcripts\"\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = f\"logs/{current_file_name}/{dt_string}.log\"\n",
    "logging.basicConfig(level=logging.INFO, filename=log_file,filemode=\"w\", format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# https://blog.sentry.io/logging-in-python-a-developers-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "import io\n",
    "\n",
    "from google.cloud import speech\n",
    "\n",
    "import grpc\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.pages import *\n",
    "from helpers.constants import *\n",
    "from helpers.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens/openai_key.txt\", \"r\") as file:\n",
    "    OPENAI_API_KEY = file.read().rstrip()\n",
    "\n",
    "# Set environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_MODE = \"openai\"\n",
    "# GLOBAL_MODE = \"google\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GLOBAL_MODE == \"google\":\n",
    "    GLOBAL_FORMAT = \".aac\"\n",
    "elif GLOBAL_MODE == \"openai\":\n",
    "    GLOBAL_FORMAT = \".wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_of_paths(root_path):\n",
    "    # There are folders in the root path named after the respondents\n",
    "    # Each of these folders contains the audio files in aac/wav format\n",
    "    # Create dictionary with the paths to the audio files, where the key is subfolder name and the value is the list of audio files\n",
    "\n",
    "    dict_of_paths = {}\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        if len(files) > 0:\n",
    "            # Only keep the audio files\n",
    "            files = [f for f in files if f.endswith(GLOBAL_FORMAT)]\n",
    "            # Full path to the audio files\n",
    "            files = [os.path.join(root, f) for f in files]\n",
    "            \n",
    "            folder_name = root.split(\"\\\\\")[-1]\n",
    "            dict_of_paths[folder_name] = files\n",
    "    return dict_of_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_recordings_fg_path = \"data\\\\6_Elaborations_Extraction\\\\FG\"\n",
    "extracted_recordings_h_path = \"data\\\\6_Elaborations_Extraction\\\\H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_paths = get_dict_of_paths(extracted_recordings_fg_path)\n",
    "h_paths = get_dict_of_paths(extracted_recordings_h_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def transcribe_onprem_google(local_file_path: str):\n",
    "    logging.info(f\"Transcribing {local_file_path}\")\n",
    "\n",
    "    # The language of the supplied audio\n",
    "    language_code = \"en-GB\"\n",
    "\n",
    "    # Sample rate in Hertz of the audio data sent\n",
    "    sample_rate_hertz = 48000\n",
    "\n",
    "    # Encoding of audio data sent. This sample sets this explicitly.\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = speech.RecognitionConfig.AudioEncoding.MP3\n",
    "\n",
    "    config = {\n",
    "        \"encoding\": encoding, # only when not using FLAC or WAV\n",
    "        \"sample_rate_hertz\": sample_rate_hertz, # only when not using FLAC or WAV\n",
    "        \"language_code\": language_code,\n",
    "        \"profanity_filter\": False,\n",
    "        \"enable_word_time_offsets\": True,\n",
    "        \"enable_word_confidence\": True,\n",
    "        \"enable_automatic_punctuation\": False,\n",
    "        \"model\": \"latest_long\",\n",
    "    }\n",
    "    with io.open(local_file_path, \"rb\") as f:\n",
    "        content = f.read()\n",
    "    audio = {\"content\": content}\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "    response = client.recognize(request={\"config\": config, \"audio\": audio})\n",
    "\n",
    "    # First alternative is the most probable result\n",
    "    concatenated_transcript = \" \".join([result.alternatives[0].transcript for result in response.results])\n",
    "\n",
    "    logging.info(f\"Transcription of {local_file_path} complete\")\n",
    "\n",
    "    return response, concatenated_transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def transcribe_onprem_openai(local_file_path: str):\n",
    "    logging.info(f\"Transcribing {local_file_path}\")\n",
    "\n",
    "    audio_file = open(local_file_path, \"rb\")\n",
    "\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "        file=audio_file,\n",
    "        model=\"whisper-1\",\n",
    "        language=\"en\",\n",
    "        response_format=\"verbose_json\",\n",
    "        temperature=0.0, \n",
    "        timestamp_granularities=[\"word\", \"segment\"],\n",
    "        prompt=\"Umm, let me think like, hmm... Okay, here's what I'm, like, thinking. Uh. Um. Well. Er. Ah. You know, like. Erm.\"\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Transcription of {local_file_path} complete\")\n",
    "\n",
    "    return transcript, transcript.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(path_dict, variant, fixing=[]):\n",
    "    # For each respondent, transcribe all the audio files and save the transcript\n",
    "    for respondent, paths in path_dict.items():\n",
    "        logging.info(f\"Transcribing {respondent}\")\n",
    "        respondent_path = f\"data\\\\7_Elaborations_Transcripts\\\\{variant}\\\\{respondent}\"\n",
    "\n",
    "        # Get all elements from fixing that has as their first element the respondent\n",
    "        fixes = [f for f in fixing if f[0] == respondent]\n",
    "\n",
    "        if len(fixes) == 0:\n",
    "            if os.path.exists(respondent_path):\n",
    "                logging.info(f\"Folder {respondent_path} already exists\")\n",
    "                continue\n",
    "            else:\n",
    "                os.makedirs(respondent_path, exist_ok=True)\n",
    "\n",
    "        for path in paths:\n",
    "            skip = True\n",
    "\n",
    "            if fixes != []:\n",
    "                skip = True\n",
    "\n",
    "                for fix in fixes:\n",
    "                    if fix[1] in path:\n",
    "                        skip = False\n",
    "                        print(f\"Fixing {path}\")\n",
    "            else:\n",
    "                skip = False\n",
    "\n",
    "            if skip:\n",
    "                continue\n",
    "\n",
    "            logging.info(f\"Transcribing {path} using {GLOBAL_MODE}\")\n",
    "\n",
    "            if GLOBAL_MODE == \"google\":\n",
    "                response, transcript = transcribe_onprem_google(path)\n",
    "            if GLOBAL_MODE == \"openai\":\n",
    "                response, transcript = transcribe_onprem_openai(path)\n",
    "\n",
    "            file_name_transcript = path.split(\"\\\\\")[-1].replace(GLOBAL_FORMAT, \".txt\")\n",
    "\n",
    "            file_name_response = path.split(\"\\\\\")[-1].replace(GLOBAL_FORMAT, \"_response.json\")\n",
    "\n",
    "            transcript_path = os.path.join(respondent_path, file_name_transcript)\n",
    "            response_path = os.path.join(respondent_path, file_name_response)\n",
    "\n",
    "            with open(transcript_path, \"w\") as f:\n",
    "                # Sanitaze transcript to remove \\ufffd\n",
    "                transcript = transcript.replace(\"\\ufffd\", \"\")\n",
    "                f.write(transcript)\n",
    "\n",
    "            if GLOBAL_MODE == \"google\":\n",
    "                with open(response_path, \"w\") as f:\n",
    "                    f.write(str(response))\n",
    "            if GLOBAL_MODE == \"openai\":\n",
    "                with open(response_path, \"w\") as f:\n",
    "\n",
    "                    try:\n",
    "                        f.write(response.model_dump_json())\n",
    "                    except:\n",
    "                        dump = response.model_dump_json()\n",
    "                        dump = dump.replace(\"\\ufffd\", \"\")\n",
    "                        f.write(dump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_fix_1 = [['respondent_104', 'elaboration_3_2'],\n",
    "            ['respondent_106', 'elaboration_1_2'],\n",
    "            ['respondent_106', 'elaboration_4_1'],\n",
    "            ['respondent_12', 'elaboration_2_2'],\n",
    "            ['respondent_12', 'elaboration_3_2'],\n",
    "            ['respondent_21', 'elaboration_3_1'],\n",
    "            ['respondent_25', 'elaboration_5_2'],\n",
    "            ['respondent_31', 'elaboration_4_1'],\n",
    "            ['respondent_35', 'elaboration_3_2'],\n",
    "            ['respondent_35', 'elaboration_4_1'],\n",
    "            ['respondent_35', 'elaboration_4_2'],\n",
    "            ['respondent_37', 'elaboration_2_2'],\n",
    "            ['respondent_38', 'elaboration_4_2'],\n",
    "            ['respondent_45', 'elaboration_1_1'],\n",
    "            ['respondent_45', 'elaboration_2_1'],\n",
    "            ['respondent_45', 'elaboration_2_2'],\n",
    "            ['respondent_45', 'elaboration_3_1'],\n",
    "            ['respondent_54', 'elaboration_3_2']]\n",
    "\n",
    "h_fix_1 = [['respondent_107', 'elaboration_1_2'],\n",
    "           ['respondent_110', 'elaboration_3_1'],\n",
    "           ['respondent_110', 'elaboration_3_2'],\n",
    "           ['respondent_22', 'elaboration_2_2'],\n",
    "           ['respondent_22', 'elaboration_4_2'],\n",
    "           ['respondent_29', 'elaboration_5_1'],\n",
    "           ['respondent_35', 'elaboration_5_1'],\n",
    "           ['respondent_42', 'elaboration_4_2'],\n",
    "           ['respondent_47', 'elaboration_1_1'],\n",
    "           ['respondent_47', 'elaboration_1_2'],\n",
    "           ['respondent_47', 'elaboration_3_2'],\n",
    "           ['respondent_47', 'elaboration_4_1'],\n",
    "           ['respondent_48', 'elaboration_1_2'],\n",
    "           ['respondent_48', 'elaboration_3_2'],\n",
    "           ['respondent_50', 'elaboration_2_2'],\n",
    "           ['respondent_55', 'elaboration_2_1'],\n",
    "           ['respondent_57', 'elaboration_5_2'],\n",
    "           ['respondent_58', 'elaboration_4_2'],\n",
    "           ['respondent_8', 'elaboration_2_2'],\n",
    "           ['respondent_8', 'elaboration_3_1'],\n",
    "           ['respondent_8', 'elaboration_3_2'],\n",
    "           ['respondent_8', 'elaboration_5_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_fix_2 = [['respondent_35', 'elaboration_4_2'],\n",
    "            ['respondent_45', 'elaboration_2_1']]\n",
    "\n",
    "\n",
    "h_fix_2 = [['respondent_29', 'elaboration_5_1'],\n",
    "           ['respondent_47', 'elaboration_1_1'],\n",
    "           ['respondent_47', 'elaboration_1_2'],\n",
    "           ['respondent_47', 'elaboration_3_2'],\n",
    "           ['respondent_47', 'elaboration_4_1'],\n",
    "           ['respondent_55', 'elaboration_2_1'],\n",
    "           ['respondent_8', 'elaboration_3_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GLOBAL_MODE == \"google\":\n",
    "    get_transcript(fg_paths, \"FG_Google\")\n",
    "if GLOBAL_MODE == \"openai\":\n",
    "    get_transcript(fg_paths, \"FG\", fg_fix_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GLOBAL_MODE == \"google\":\n",
    "    get_transcript(h_paths, \"H_Google\")\n",
    "if GLOBAL_MODE == \"openai\":\n",
    "    get_transcript(h_paths, \"H\", h_fix_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
