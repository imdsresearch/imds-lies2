{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "current_file_name = \"13_Mouse_Data_Preparation\"\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = f\"logs/{current_file_name}/{dt_string}.log\"\n",
    "logging.basicConfig(level=logging.INFO, filename=log_file,filemode=\"w\", format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# https://blog.sentry.io/logging-in-python-a-developers-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.questions import *\n",
    "from helpers.constants import *\n",
    "from helpers.pages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajecotires_from_csv(csv_df, pages):\n",
    "    page_names = pages.keys()\n",
    "\n",
    "    csv_dict = {}\n",
    "\n",
    "    for page_name in page_names:\n",
    "        page = csv_df[csv_df[\"page_name\"] == page_name]\n",
    "        csv_dict[page_name] = page\n",
    "\n",
    "    return csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_trajectories_from_interactions(path, pages):\n",
    "    # Traverse through all files in the directory\n",
    "    folders = os.listdir(path)\n",
    "    \n",
    "    interactions_dict = {}\n",
    "\n",
    "    for folder in folders:\n",
    "        files = os.listdir(path + \"\\\\\" + folder)\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_df = pd.read_csv(path + \"\\\\\" + folder + \"\\\\\" + file)\n",
    "\n",
    "                # Get number from the folder name\n",
    "                number = folder.split(\"_\")[1]\n",
    "                answers_dict = get_trajecotires_from_csv(csv_df, pages)\n",
    "                interactions_dict[number] = answers_dict\n",
    "    return interactions_dict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fg = 'data\\\\3_UXtweak_Mouse_Data_Processing\\\\FG'\n",
    "path_h = 'data\\\\3_UXtweak_Mouse_Data_Processing\\\\H'\n",
    "\n",
    "extracted_fg = exctract_trajectories_from_interactions(path_fg, pages)\n",
    "extracted_fg[\"group\"] = \"FG\"\n",
    "\n",
    "extracted_h = exctract_trajectories_from_interactions(path_h, pages)\n",
    "extracted_h[\"group\"] = \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_width = 1920\n",
    "normal_height = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_widt_and_height(page_df):\n",
    "    return page_df[\"pageview_screenWidth\"].iloc[0], page_df[\"pageview_screenHeight\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scrolling(page_df):\n",
    "    different = False\n",
    "    \n",
    "    # Compare clientX with x and clientY with y\n",
    "    for index, row in page_df.iterrows():\n",
    "        if row[\"clientX\"] != row[\"x\"]:\n",
    "            different = True\n",
    "        if row[\"clientY\"] != row[\"y\"]:\n",
    "            different = True\n",
    "\n",
    "    return different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_time(page_df):\n",
    "    # Trajectory starts with first move\n",
    "\n",
    "    start_time = page_df[\"accurate_timestamp\"].min()\n",
    "    \n",
    "    page_df.loc[:, \"accurate_timestamp\"] = page_df[\"accurate_timestamp\"] - start_time\n",
    "    return page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_trajectory(page_df, width, height, normal_width, normal_height):\n",
    "    page_df.loc[:, \"clientX\"] = page_df[\"clientX\"] / width * normal_width\n",
    "    page_df.loc[:, \"clientY\"] = (height - page_df[\"clientY\"]) / height * normal_height\n",
    "    return page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_from_page(page_df):\n",
    "    page_df = page_df[[\"clientX\", \"clientY\", \"accurate_timestamp\", \"type\", \"text\"]]\n",
    "    return page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(page, normal_width, normal_height):\n",
    "    page_df = page.copy(deep=True)\n",
    "    width, height = get_widt_and_height(page_df)\n",
    "    if check_scrolling(page_df):\n",
    "        print(\"Scrolling\")\n",
    "    page_df = restart_time(page_df)\n",
    "    page_df = normalize_trajectory(page_df, width, height, normal_width, normal_height)\n",
    "    page_df = get_trajectory_from_page(page_df)\n",
    "    return page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = extracted_fg[\"26\"][\"page_5\"]\n",
    "page_df = process_page(page, normal_width, normal_height)\n",
    "page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average difference between timestamps in ms\n",
    "page_df[\"accurate_timestamp\"].diff().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(df):\n",
    "    page_df = df.copy(deep=True)\n",
    "    \n",
    "    page_df[\"distance\"] = np.sqrt((page_df[\"clientX\"] - page_df[\"clientX\"].shift())**2 + (page_df[\"clientY\"] - page_df[\"clientY\"].shift())**2)\n",
    "    return page_df[\"distance\"].sum().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_axis_distance(df, axis):\n",
    "    page_df = df.copy(deep=True)\n",
    "\n",
    "    page_df[\"distance\"] = np.abs(page_df[axis] - page_df[axis].shift())\n",
    "    return page_df[\"distance\"].sum().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flips(df, axis):\n",
    "    page_df = df.copy(deep=True)\n",
    "    # Check for direction change\n",
    "\n",
    "    page_df[\"direction\"] = np.sign(page_df[axis] - page_df[axis].shift())\n",
    "\n",
    "    # Remove rows without change in direction \n",
    "    page_df = page_df[page_df[\"direction\"] != 0]\n",
    "\n",
    "    page_df[\"flips\"] = page_df[\"direction\"] != page_df[\"direction\"].shift()\n",
    "\n",
    "    # Unable to get direction of first coordinate, direction is based on the previous coorditate, in this case it does not exist\n",
    "    # Unable to get flip value of second coordinate, because it is calculated based on change between directions of first and second coordinates\n",
    "    # First 2 flip values are true, so they need to be discarded\n",
    "    return page_df[\"flips\"].sum() - 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ideal_trajectory_coordinates(df):\n",
    "    page_df = df.copy(deep=True)\n",
    "\n",
    "    first_move = page_df[page_df[\"type\"] == \"move\"].iloc[0]\n",
    "    first_x = first_move[\"clientX\"]\n",
    "    first_y = first_move[\"clientY\"]\n",
    "\n",
    "    last_answer = page_df[page_df[\"text\"].notna() & (page_df[\"text\"] != \"Next\")]\n",
    "    last_x = last_answer[\"clientX\"].iloc[0]\n",
    "    last_y = last_answer[\"clientY\"].iloc[0]\n",
    "    last_time = last_answer[\"accurate_timestamp\"].iloc[0]\n",
    "\n",
    "    return first_x, first_y, last_x, last_y, last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_trajectory_length(df):\n",
    "    page_df = df.copy(deep=True)\n",
    "\n",
    "    first_x, first_y, last_x, last_y, last_time = _ideal_trajectory_coordinates(page_df)\n",
    "    return np.sqrt((last_x - first_x)**2 + (last_y - first_y)**2).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_deviation(df):\n",
    "    page_df = df.copy(deep=True)\n",
    "    \n",
    "    first_x, first_y, last_x, last_y, last_time = _ideal_trajectory_coordinates(page_df)\n",
    "    # Only consider time up to the last answer\n",
    "    page_df = page_df[page_df[\"accurate_timestamp\"] <= last_time]\n",
    "\n",
    "    # https://en.wikipedia.org/wiki/Distance_from_a_point_to_a_line#Line_defined_by_two_points\n",
    "    page_df.loc[:, \"deviation\"] = np.abs((last_x - first_x) * (page_df[\"clientY\"] - first_y) - (last_y - first_y) * (page_df[\"clientX\"] - first_x) ) / np.sqrt((last_y - first_y)**2 + (last_x - first_x)**2)\n",
    "\n",
    "    return page_df[\"deviation\"].max().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_under_curve(df, mode, test=False):\n",
    "    page_df = df.copy(deep=True)\n",
    "\n",
    "    if not test:\n",
    "        first_x, first_y, last_x, last_y, last_time = _ideal_trajectory_coordinates(page_df)\n",
    "        page_df = page_df[page_df[\"accurate_timestamp\"] <= last_time]\n",
    "\n",
    "    # https://en.wikipedia.org/wiki/Trapezoidal_rule\n",
    "\n",
    "    if mode == \"real\":\n",
    "        page_df.loc[:, \"area\"] = 0.5 * (page_df[\"clientX\"] - page_df[\"clientX\"].shift()) * (page_df[\"clientY\"] + page_df[\"clientY\"].shift())\n",
    "        return page_df[\"area\"].sum().round(2)\n",
    "    \n",
    "    if mode == \"ideal\":\n",
    "        return (0.5 * (last_x - first_x) * (last_y + first_y)).round(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.emathhelp.net/en/calculators/calculus-2/trapezoidal-rule-calculator-for-a-table/?i=%5B%5B1%2C6%2C3%2C10%2C12%2C2%5D%2C%5B15%2C5%2C3%2C1%2C47%2C6%5D%5D\n",
    "\n",
    "test_auc = pd.DataFrame({\"clientX\": [1, 2, 3, 6, 10, 12], \"clientY\": [15, 6, 3, 5, 1, 47]})\n",
    "area_under_curve(test_auc, mode=\"real\", test=True) # 87.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_metrics(page_df):\n",
    "    metrics = {}\n",
    "\n",
    "    # Duration of the page\n",
    "    metrics[\"total_duration\"] = page_df[\"accurate_timestamp\"].iloc[-1]\n",
    "\n",
    "    # Time until first movement\n",
    "    metrics[\"init_time\"] = page_df[page_df[\"type\"] == \"move\"][\"accurate_timestamp\"].iloc[0]\n",
    "    \n",
    "    # Time until final decision (text is not NaN, text is no Next)\n",
    "    metrics[\"react_time\"] = page_df[page_df[\"text\"].notna() & (page_df[\"text\"] != \"Next\")][\"accurate_timestamp\"].iloc[0]\n",
    "\n",
    "    # Number of clicks\n",
    "    metrics[\"number_of_clicks\"] = page_df[page_df[\"type\"] == \"click\"].shape[0]\n",
    "\n",
    "    # Number of x-flips\n",
    "    metrics[\"number_of_x_flips\"] = calculate_flips(page_df, \"clientX\")\n",
    "\n",
    "    # Number of y-flips\n",
    "    metrics[\"number_of_y_flips\"] = calculate_flips(page_df, \"clientY\")\n",
    "\n",
    "    # Distance of the mouse movement\n",
    "    metrics[\"distance\"] = calculate_distance(page_df)\n",
    "\n",
    "    # Distance of the mouse movement on the x axis\n",
    "    metrics[\"distance_x\"] = calculate_axis_distance(page_df, \"clientX\")\n",
    "\n",
    "    # Distance of the mouse movement on the y axis\n",
    "    metrics[\"distance_y\"] = calculate_axis_distance(page_df, \"clientY\")\n",
    "\n",
    "    # Speed of the mouse movement\n",
    "    metrics[\"speed\"] = metrics[\"distance\"] / metrics[\"total_duration\"]\n",
    "\n",
    "    # Speed of the mouse movement on the x axis\n",
    "    metrics[\"speed_x\"] = metrics[\"distance_x\"] / metrics[\"total_duration\"]\n",
    "\n",
    "    # Speed of the mouse movement on the y axis\n",
    "    metrics[\"speed_y\"] = metrics[\"distance_y\"] / metrics[\"total_duration\"]\n",
    "\n",
    "    # Acceleration of the mouse movement\n",
    "    metrics[\"acceleration\"] = metrics[\"speed\"] / metrics[\"total_duration\"]\n",
    "\n",
    "    # Acceleration of the mouse movement on the x axis\n",
    "    metrics[\"acceleration_x\"] = metrics[\"speed_x\"] / metrics[\"total_duration\"]\n",
    "\n",
    "    # Acceleration of the mouse movement on the y axis\n",
    "    metrics[\"acceleration_y\"] = metrics[\"speed_y\"] / metrics[\"total_duration\"]\n",
    "\n",
    "    # Ideal trajectory length (straight line between first movement and final decision)\n",
    "    metrics[\"ideal_trajectory_length\"] = ideal_trajectory_length(page_df)\n",
    "\n",
    "    # Max deviation from the ideal trajectory\n",
    "    metrics[\"max_deviation\"] = max_deviation(page_df)\n",
    "\n",
    "    # Area under the real curve\n",
    "    metrics[\"area_under_real_curve\"] = area_under_curve(page_df, mode=\"real\")\n",
    "\n",
    "    # Area under the optimal curve\n",
    "    metrics[\"area_under_ideal_curve\"] = area_under_curve(page_df, mode=\"ideal\")\n",
    "\n",
    "    # Difference between the two areas\n",
    "    metrics[\"area_difference\"] = (metrics[\"area_under_real_curve\"] - metrics[\"area_under_ideal_curve\"]).round(2)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_page_metrics(page_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_trajectory(df, interval=10):\n",
    "    page_df = df.copy(deep=True)\n",
    "\n",
    "    new_timestamps = np.arange(page_df['accurate_timestamp'].min(), page_df['accurate_timestamp'].max(), interval)\n",
    "\n",
    "    # Create interpolation functions for x and y\n",
    "    f_x = interp1d(page_df['accurate_timestamp'], page_df['clientX'], kind='linear', fill_value=\"extrapolate\")\n",
    "    f_y = interp1d(page_df['accurate_timestamp'], page_df['clientY'], kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "    # Apply functions to interpolate at new timestamps\n",
    "    interpolated_x = f_x(new_timestamps)\n",
    "    interpolated_y = f_y(new_timestamps)\n",
    "\n",
    "    # Round interpolated values to integers\n",
    "    interpolated_x = np.round(interpolated_x).astype(int)\n",
    "    interpolated_y = np.round(interpolated_y).astype(int)\n",
    "\n",
    "    # Create a new DataFrame with interpolated values\n",
    "    interpolated_data = pd.DataFrame({\n",
    "        'interpolated_timestamp': new_timestamps,\n",
    "        'seconds': new_timestamps / 1000,\n",
    "        'x': interpolated_x,\n",
    "        'y': interpolated_y\n",
    "    })\n",
    "\n",
    "    return interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_trajectory = interpolate_trajectory(page_df, interval=25)\n",
    "interpolated_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make animation\n",
    "fig = px.scatter(interpolated_trajectory, x='x', y='y', animation_frame='seconds', range_x=[0, normal_width], range_y=[0, normal_height])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deltas(df):\n",
    "    page_df = df.copy(deep=True)\n",
    "\n",
    "    page_df['delta_x'] = df['x'].diff()\n",
    "    page_df['delta_y'] = df['y'].diff()\n",
    "\n",
    "    # Handle the NaN values that appear in the first row from the diff operation\n",
    "    page_df = page_df.bfill()\n",
    "\n",
    "    # Convert to integers\n",
    "    page_df['delta_x'] = page_df['delta_x'].astype(int)\n",
    "    page_df['delta_y'] = page_df['delta_y'].astype(int)\n",
    "\n",
    "    return page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_deltas(interpolated_trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_pages = []\n",
    "question_indices = []\n",
    "\n",
    "start = 2\n",
    "end = 14\n",
    "counter = 0\n",
    "\n",
    "for index, page_name in enumerate(pages.keys()):\n",
    "    if index + 1 in range(start, end):\n",
    "        counter += 1\n",
    "        question_pages.append(page_name)\n",
    "        question_indices.append(index)\n",
    "    if counter == 12:\n",
    "        start += 17\n",
    "        end += 17\n",
    "        counter = 0\n",
    "    if start > 80:\n",
    "        break\n",
    "\n",
    "print(question_pages)\n",
    "print(len(question_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dict_events, variant, normal_width, normal_height, question_pages):\n",
    "    # Disable SettingWithCopyWarning\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    \n",
    "    output_metrics_list = []\n",
    "    output_trajectories_df = pd.DataFrame()\n",
    "\n",
    "    for respondent, pages in dict_events.items():\n",
    "        if type(pages) == str:\n",
    "            continue\n",
    "        for page_name, page_df in pages.items():\n",
    "            if page_name not in question_pages:\n",
    "                continue\n",
    "            if page_df.empty:\n",
    "                continue\n",
    "            page_df = process_page(page_df, normal_width, normal_height)\n",
    "            metrics = get_page_metrics(page_df)\n",
    "            metrics[\"respondent\"] = f\"respondent_{respondent}\"\n",
    "            metrics[\"page_name\"] = page_name\n",
    "            metrics[\"variant\"] = variant\n",
    "\n",
    "            output_metrics_list.append(metrics)\n",
    "            logging.info(f\"Metrics processed for Participant {respondent} Page {page_name} Group {variant}\")\n",
    "\n",
    "            interpolated_trajectory = interpolate_trajectory(page_df, interval=25)\n",
    "            interpolated_trajectory = calculate_deltas(interpolated_trajectory)\n",
    "            interpolated_trajectory[\"respondent\"] = f\"respondent_{respondent}\"\n",
    "            interpolated_trajectory[\"page_name\"] = page_name\n",
    "            interpolated_trajectory[\"variant\"] = variant\n",
    "\n",
    "            output_trajectories_df = pd.concat([output_trajectories_df, interpolated_trajectory], ignore_index=True)\n",
    "            logging.info(f\"Trajectory interpolated for Participant {respondent} Page {page_name} Group {variant}\")\n",
    "\n",
    "    return pd.DataFrame(output_metrics_list), output_trajectories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_metrics_fg, processed_trajectories_fg = create_dataset(extracted_fg, \"FG\", normal_width, normal_height, question_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_metrics_h, processed_trajectories_h = create_dataset(extracted_h, \"H\", normal_width, normal_height, question_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_metrics_fg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_trajectories_fg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_pre_study_questions_path = wd + \"\\\\2 UXtweak CSVs\\\\[DP Lies] Final 1 FG\\\\[DP Lies] Final 1 FG - Pre-study questionnaire.csv\"\n",
    "h_pre_study_questions_path = wd + \"\\\\2 UXtweak CSVs\\\\[DP Lies] Final 1 H\\\\[DP Lies] Final 1 H - Pre-study questionnaire.csv\"\n",
    "fg_pre_study_questions = pd.read_csv(fg_pre_study_questions_path)\n",
    "h_pre_study_questions = pd.read_csv(h_pre_study_questions_path)\n",
    "\n",
    "fg_pre_study_questions_path_pilot = wd_pilot + \"\\\\2 UXtweak CSVs\\\\Pilot Demo 4 FG\\\\Pilot Demo 4 FG - Pre-study questionnaire.csv\"\n",
    "h_pre_study_questions_path_pilot = wd_pilot + \"\\\\2 UXtweak CSVs\\\\Pilot Demo 4 H\\\\Pilot Demo 4 H - Pre-study questionnaire.csv\"\n",
    "fg_pre_study_questions_pilot = pd.read_csv(fg_pre_study_questions_path_pilot)\n",
    "h_pre_study_questions_pilot = pd.read_csv(h_pre_study_questions_path_pilot)\n",
    "\n",
    "fg_pre_study_questions = pd.concat([fg_pre_study_questions, fg_pre_study_questions_pilot])\n",
    "h_pre_study_questions = pd.concat([h_pre_study_questions, h_pre_study_questions_pilot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fg_pre_study_questions[\"Q1: What gender do you identify as?\"].unique())\n",
    "print(h_pre_study_questions[\"Q1: What gender do you identify as?\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_female(pre_study_questions):\n",
    "    pre_study_questions[\"female\"] = pre_study_questions[\"Q1: What gender do you identify as?\"] == \"Female\"\n",
    "    pre_study_questions = pre_study_questions[[\"respondent\", \"female\"]]\n",
    "    pre_study_questions.rename(columns={\"respondent\": \"respondent_num\"}, inplace=True)\n",
    "    pre_study_questions[\"respondent\"] = pre_study_questions[\"respondent_num\"].apply(lambda x: \"respondent_\" + str(x))\n",
    "    return pre_study_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_female = check_if_female(fg_pre_study_questions)\n",
    "h_female = check_if_female(h_pre_study_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_female_to_df(df, female_df):\n",
    "    # Add the same value of female to all pages of the same respondent, merge many to one\n",
    "    merged_df = pd.merge(df, female_df, on='respondent', how='left')\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_metrics_fg = add_female_to_df(processed_metrics_fg, fg_female)\n",
    "gendered_metrics_h = add_female_to_df(processed_metrics_h, h_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unifnished questionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If number of pages for each respondent is not 60, remove them\n",
    "fg_respondents_counts = gendered_metrics_fg[\"respondent\"].value_counts()\n",
    "fg_respondents_to_drop = fg_respondents_counts[fg_respondents_counts != 60].index.values.tolist()\n",
    "fg_respondents_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unfinished questionnaires from fg\n",
    "fg_metrics_len = len(gendered_metrics_fg)\n",
    "fg_trajectories_len = len(processed_trajectories_fg)\n",
    "\n",
    "gendered_metrics_fg = gendered_metrics_fg[~gendered_metrics_fg[\"respondent\"].isin(fg_respondents_to_drop)]\n",
    "processed_trajectories_fg = processed_trajectories_fg[~processed_trajectories_fg[\"respondent\"].isin(fg_respondents_to_drop)]\n",
    "\n",
    "print(\"gendered_metrics_fg difference\", fg_metrics_len - len(gendered_metrics_fg))\n",
    "print(\"processed_trajectories_fg difference\", fg_trajectories_len - len(processed_trajectories_fg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If number of pages for each respondent is not 60, remove them\n",
    "h_respondents_counts = gendered_metrics_h[\"respondent\"].value_counts()\n",
    "h_respondents_to_drop = h_respondents_counts[h_respondents_counts != 60].index.values.tolist()\n",
    "h_respondents_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unfinished questionnaires from h\n",
    "h_metrics_len = len(gendered_metrics_h)\n",
    "h_trajectories_len = len(processed_trajectories_h)\n",
    "\n",
    "gendered_metrics_h = gendered_metrics_h[~gendered_metrics_h[\"respondent\"].isin(h_respondents_to_drop)]\n",
    "processed_trajectories_h = processed_trajectories_h[~processed_trajectories_h[\"respondent\"].isin(h_respondents_to_drop)]\n",
    "\n",
    "print(\"gendered_metrics_h difference\", h_metrics_len - len(gendered_metrics_h))\n",
    "print(\"processed_trajectories_h difference\", h_trajectories_len - len(processed_trajectories_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes with metrics\n",
    "merged_metrics_dataframes = pd.concat([gendered_metrics_fg, gendered_metrics_h])\n",
    "len(merged_metrics_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes with trajectories\n",
    "merged_trajectories_dataframes = pd.concat([processed_trajectories_fg, processed_trajectories_h])\n",
    "len(merged_trajectories_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_names = [f\"question_{x}\" for x in range(1, len(question_indices) + 1)]\n",
    "answer_column = [f\"rbfi{x}\" if x in glob_reversed_questions else f\"bfi{x}\" for x in range(1, len(question_indices) + 1)]\n",
    "\n",
    "print(len(glob_big5_questions), len(question_names), len(answer_column))\n",
    "questions_dict_answers = {f\"page_{question_indices[i] + 1}\": (answer_column[i], glob_big5_questions[i]) for i in range(len(question_indices))}\n",
    "\n",
    "questions_dict_answers[\"page_81\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dict_answers_gt = {}\n",
    "\n",
    "for key, value in questions_dict_answers.items():\n",
    "    questions_dict_answers_gt[key] = value[0] + \"_gt\"\n",
    "\n",
    "questions_dict_answers_gt[\"page_81\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elaborations_dict_reversed = {value: key for key, value in questions_dict_answers_gt.items()}\n",
    "elaborations_dict_reversed[\"bfi60_gt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_columns = [value for key, value in questions_dict_answers_gt.items()]\n",
    "\n",
    "ground_truth_columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_columns_reversed = [value for key, value in elaborations_dict_reversed.items()]\n",
    "\n",
    "ground_truth_columns_reversed[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_path = \"data\\\\4_Pair_UXtweak_and_SurveyJS\\\\4_Pair_UXtweak_and_SurveyJS_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_df = pd.read_csv(pairing_path)\n",
    "pairing_df = pairing_df[[\"group_evaluated\", \"order\"] + ground_truth_columns]\n",
    "# Rename group_evaluated to variant and order to respondent\n",
    "pairing_df = pairing_df.rename(columns={\"group_evaluated\": \"variant\", \"order\": \"respondent\"})\n",
    "# Replace 0.5 with 1\n",
    "pairing_df = pairing_df.replace(0.5, 1)\n",
    "# Add prefix respondent_ to values in order column\n",
    "pairing_df[\"respondent\"] = \"respondent_\" + pairing_df[\"respondent\"].astype(str)\n",
    "# Rename ground truth columns to match the ones in aggregated dataframes\n",
    "pairing_df = pairing_df.rename(columns=elaborations_dict_reversed)\n",
    "# Each elaboration should be in a separate row\n",
    "pairing_df = pairing_df.melt(id_vars=[\"variant\", \"respondent\"], value_vars=ground_truth_columns_reversed, var_name=\"page_name\", value_name=\"indicator_fg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_df.groupby(\"indicator_fg\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_df[pairing_df[\"indicator_fg\"] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_df[\"control\"] = \"control\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_df[pairing_df[\"variant\"] == \"FG\"][\"respondent\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairing_df[pairing_df[\"variant\"] == \"H\"][\"respondent\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_pairing_df_respondents_counts = pairing_df[pairing_df[\"variant\"] == \"FG\"][\"respondent\"].value_counts()\n",
    "fg_pairing_df_respondents_to_drop = fg_pairing_df_respondents_counts[fg_pairing_df_respondents_counts != 60].index.values.tolist()\n",
    "fg_pairing_df_respondents_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pairing_df_respondents_counts = pairing_df[pairing_df[\"variant\"] == \"H\"][\"respondent\"].value_counts()\n",
    "h_pairing_df_respondents_to_drop = h_pairing_df_respondents_counts[h_pairing_df_respondents_counts != 60].index.values.tolist()\n",
    "h_pairing_df_respondents_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Ground Truth to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"merged_metrics_dataframes {len(merged_metrics_dataframes)}\")\n",
    "print(f\"merged_trajectories_dataframes {len(merged_trajectories_dataframes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_metrics_enriched = pd.merge(merged_metrics_dataframes, pairing_df, on=[\"variant\", \"respondent\", \"page_name\"], how=\"outer\")\n",
    "merged_trajectories_enriched = pd.merge(merged_trajectories_dataframes, pairing_df, on=[\"variant\", \"respondent\", \"page_name\"], how=\"outer\")\n",
    "\n",
    "print(f\"merged_metrics_enriched {len(merged_metrics_enriched)}\")\n",
    "print(f\"merged_trajectories_enriched {len(merged_trajectories_enriched)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_metrics_enriched[merged_metrics_enriched[\"indicator_fg\"].isna()][[\"variant\", \"respondent\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trajectories_enriched[merged_trajectories_enriched[\"indicator_fg\"].isna()][[\"variant\", \"respondent\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in ground_truth column\n",
    "merged_metrics_enriched = merged_metrics_enriched.dropna(subset=[\"indicator_fg\"])\n",
    "merged_metrics_enriched = merged_metrics_enriched[merged_metrics_enriched[\"control\"] == \"control\"].drop(columns=[\"control\"])\n",
    "\n",
    "print(f\"merged_metrics_enriched {len(merged_metrics_enriched)}\")\n",
    "merged_metrics_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in ground_truth column\n",
    "merged_trajectories_enriched = merged_trajectories_enriched.dropna(subset=[\"indicator_fg\"])\n",
    "merged_trajectories_enriched = merged_trajectories_enriched[merged_trajectories_enriched[\"control\"] == \"control\"].drop(columns=[\"control\"])\n",
    "\n",
    "print(f\"merged_trajectories_enriched {len(merged_trajectories_enriched)}\")\n",
    "merged_trajectories_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_metrics_enriched[merged_metrics_enriched[\"variant\"] == \"FG\"][\"respondent\"].nunique())\n",
    "print(merged_metrics_enriched[merged_metrics_enriched[\"variant\"] == \"FG\"][\"respondent\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_metrics_enriched[merged_metrics_enriched[\"variant\"] == \"H\"][\"respondent\"].nunique())\n",
    "print(merged_metrics_enriched[merged_metrics_enriched[\"variant\"] == \"H\"][\"respondent\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_trajectories_enriched[merged_trajectories_enriched[\"variant\"] == \"FG\"][\"respondent\"].nunique())\n",
    "print(merged_trajectories_enriched[merged_trajectories_enriched[\"variant\"] == \"FG\"][\"respondent\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_trajectories_enriched[merged_trajectories_enriched[\"variant\"] == \"H\"][\"respondent\"].nunique())\n",
    "print(merged_trajectories_enriched[merged_trajectories_enriched[\"variant\"] == \"H\"][\"respondent\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of dropped metrics:\", len(merged_metrics_dataframes) - len(merged_metrics_enriched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of dropped trajectories:\", len(merged_trajectories_dataframes) - len(merged_trajectories_enriched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_metrics_enriched.groupby([\"variant\", \"respondent\", \"page_name\"]).count()[\"indicator_fg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trajectories_enriched.groupby([\"variant\", \"respondent\", \"page_name\"]).count()[\"indicator_fg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_metrics = merged_metrics_enriched.groupby([\"variant\", \"respondent\", \"page_name\"]).sum()    \n",
    "check_metrics = check_metrics[check_metrics[\"indicator_fg\"] == 0]\n",
    "check_metrics.groupby([\"variant\", \"respondent\"]).count()[\"indicator_fg\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_trajectories = merged_trajectories_enriched.groupby([\"variant\", \"respondent\", \"page_name\"]).sum()\n",
    "check_trajectories = check_trajectories[check_trajectories[\"indicator_fg\"] == 0]\n",
    "check_trajectories.groupby([\"variant\", \"respondent\"]).count()[\"indicator_fg\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_metrics_enriched[merged_metrics_enriched[\"variant\"] == \"FG\"][\"indicator_fg\"].sum(), merged_metrics_enriched[merged_metrics_enriched[\"variant\"] == \"H\"][\"indicator_fg\"].sum(), len(merged_metrics_enriched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_trajectories_enriched[merged_trajectories_enriched[\"variant\"] == \"FG\"][\"indicator_fg\"].sum(), merged_trajectories_enriched[merged_trajectories_enriched[\"variant\"] == \"H\"][\"indicator_fg\"].sum(), len(merged_trajectories_enriched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of counts of indicator_fg per variant\n",
    "table_metrics = pd.pivot_table(merged_metrics_enriched, values='indicator_fg', index=['variant'], aggfunc=np.sum)\n",
    "table_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of counts of indicator_fg per variant\n",
    "table_trajectories = pd.pivot_table(merged_trajectories_enriched, values='indicator_fg', index=['variant'], aggfunc=np.sum)\n",
    "table_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_metrics_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trajectories_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"merged_metrics_enriched\", len(merged_metrics_enriched))\n",
    "print(\"merged_trajectories_enriched\", len(merged_trajectories_enriched))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_metrics = \"data\\\\13_Mouse_Data_Preparation\\\\metrics_data.csv\"\n",
    "path_to_save_trajectories = \"data\\\\13_Mouse_Data_Preparation\\\\trajectories_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed metrics data\n",
    "merged_metrics_enriched.to_csv(path_to_save_metrics, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed trajectories data\n",
    "merged_trajectories_enriched.to_csv(path_to_save_trajectories, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
